[2024-06-22 15:12:18,255] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[2024-06-22 15:12:20,069] [INFO] [runner.py:463:main] Using IP address of 10.64.8.35 for node 10.64.8.35
[2024-06-22 15:12:20,069] [INFO] [runner.py:568:main] cmd = /data2/rlhf/liufeng/miniconda3/envs/yzy-rl-dev/bin/python -u -m deepspeed.launcher.launch --world_info=eyIxMC42NC44LjM1IjogWzAsIDEsIDIsIDMsIDQsIDUsIDYsIDddfQ== --master_addr=10.64.8.35 --master_port=29500 --enable_each_rank_log=None ../../examples/train_sft.py --save_path /data2/rlhf/yzy/OpenRLHF-new/outputs/reward_models/Qwen_SFT_0622 --logging_steps 10 --micro_train_batch_size 16 --train_batch_size 128 --pretrain /data2/rlhf/lixs/open_models/Qwen2-7B-Instruct/ --bf16 --max_epochs 1 --max_len 6400 --zero_stage 3 --eval_steps 250 --learning_rate 1e-5 --dataset /data2/rlhf/yzy/analysis/output/gpt-4-preview.train.jsonl --eval_dataset /data2/rlhf/yzy/analysis/output/gpt-4-preview.valid.jsonl --dataset_probs 1.0 --flash_attn --gradient_checkpointing --use_wandb a77607626908409e45afa2ca225cf179e9a316fc --wandb_run_name Qwen_SFT_0622 --wandb_project rl
[2024-06-22 15:12:23,977] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[2024-06-22 15:12:25,528] [INFO] [launch.py:139:main] 0 NCCL_VERSION=2.19.3
[2024-06-22 15:12:25,529] [INFO] [launch.py:146:main] WORLD INFO DICT: {'10.64.8.35': [0, 1, 2, 3, 4, 5, 6, 7]}
[2024-06-22 15:12:25,529] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-06-22 15:12:25,529] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'10.64.8.35': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-06-22 15:12:25,529] [INFO] [launch.py:164:main] dist_world_size=8
[2024-06-22 15:12:25,529] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2024-06-22 15:12:25,529] [INFO] [launch.py:256:main] process 109490 spawned with command: ['/data2/rlhf/liufeng/miniconda3/envs/yzy-rl-dev/bin/python', '-u', '../../examples/train_sft.py', '--local_rank=0', '--save_path', '/data2/rlhf/yzy/OpenRLHF-new/outputs/reward_models/Qwen_SFT_0622', '--logging_steps', '10', '--micro_train_batch_size', '16', '--train_batch_size', '128', '--pretrain', '/data2/rlhf/lixs/open_models/Qwen2-7B-Instruct/', '--bf16', '--max_epochs', '1', '--max_len', '6400', '--zero_stage', '3', '--eval_steps', '250', '--learning_rate', '1e-5', '--dataset', '/data2/rlhf/yzy/analysis/output/gpt-4-preview.train.jsonl', '--eval_dataset', '/data2/rlhf/yzy/analysis/output/gpt-4-preview.valid.jsonl', '--dataset_probs', '1.0', '--flash_attn', '--gradient_checkpointing', '--use_wandb', 'a77607626908409e45afa2ca225cf179e9a316fc', '--wandb_run_name', 'Qwen_SFT_0622', '--wandb_project', 'rl']
[2024-06-22 15:12:25,529] [INFO] [launch.py:256:main] process 109491 spawned with command: ['/data2/rlhf/liufeng/miniconda3/envs/yzy-rl-dev/bin/python', '-u', '../../examples/train_sft.py', '--local_rank=1', '--save_path', '/data2/rlhf/yzy/OpenRLHF-new/outputs/reward_models/Qwen_SFT_0622', '--logging_steps', '10', '--micro_train_batch_size', '16', '--train_batch_size', '128', '--pretrain', '/data2/rlhf/lixs/open_models/Qwen2-7B-Instruct/', '--bf16', '--max_epochs', '1', '--max_len', '6400', '--zero_stage', '3', '--eval_steps', '250', '--learning_rate', '1e-5', '--dataset', '/data2/rlhf/yzy/analysis/output/gpt-4-preview.train.jsonl', '--eval_dataset', '/data2/rlhf/yzy/analysis/output/gpt-4-preview.valid.jsonl', '--dataset_probs', '1.0', '--flash_attn', '--gradient_checkpointing', '--use_wandb', 'a77607626908409e45afa2ca225cf179e9a316fc', '--wandb_run_name', 'Qwen_SFT_0622', '--wandb_project', 'rl']
[2024-06-22 15:12:25,530] [INFO] [launch.py:256:main] process 109492 spawned with command: ['/data2/rlhf/liufeng/miniconda3/envs/yzy-rl-dev/bin/python', '-u', '../../examples/train_sft.py', '--local_rank=2', '--save_path', '/data2/rlhf/yzy/OpenRLHF-new/outputs/reward_models/Qwen_SFT_0622', '--logging_steps', '10', '--micro_train_batch_size', '16', '--train_batch_size', '128', '--pretrain', '/data2/rlhf/lixs/open_models/Qwen2-7B-Instruct/', '--bf16', '--max_epochs', '1', '--max_len', '6400', '--zero_stage', '3', '--eval_steps', '250', '--learning_rate', '1e-5', '--dataset', '/data2/rlhf/yzy/analysis/output/gpt-4-preview.train.jsonl', '--eval_dataset', '/data2/rlhf/yzy/analysis/output/gpt-4-preview.valid.jsonl', '--dataset_probs', '1.0', '--flash_attn', '--gradient_checkpointing', '--use_wandb', 'a77607626908409e45afa2ca225cf179e9a316fc', '--wandb_run_name', 'Qwen_SFT_0622', '--wandb_project', 'rl']
[2024-06-22 15:12:25,530] [INFO] [launch.py:256:main] process 109493 spawned with command: ['/data2/rlhf/liufeng/miniconda3/envs/yzy-rl-dev/bin/python', '-u', '../../examples/train_sft.py', '--local_rank=3', '--save_path', '/data2/rlhf/yzy/OpenRLHF-new/outputs/reward_models/Qwen_SFT_0622', '--logging_steps', '10', '--micro_train_batch_size', '16', '--train_batch_size', '128', '--pretrain', '/data2/rlhf/lixs/open_models/Qwen2-7B-Instruct/', '--bf16', '--max_epochs', '1', '--max_len', '6400', '--zero_stage', '3', '--eval_steps', '250', '--learning_rate', '1e-5', '--dataset', '/data2/rlhf/yzy/analysis/output/gpt-4-preview.train.jsonl', '--eval_dataset', '/data2/rlhf/yzy/analysis/output/gpt-4-preview.valid.jsonl', '--dataset_probs', '1.0', '--flash_attn', '--gradient_checkpointing', '--use_wandb', 'a77607626908409e45afa2ca225cf179e9a316fc', '--wandb_run_name', 'Qwen_SFT_0622', '--wandb_project', 'rl']
[2024-06-22 15:12:25,531] [INFO] [launch.py:256:main] process 109494 spawned with command: ['/data2/rlhf/liufeng/miniconda3/envs/yzy-rl-dev/bin/python', '-u', '../../examples/train_sft.py', '--local_rank=4', '--save_path', '/data2/rlhf/yzy/OpenRLHF-new/outputs/reward_models/Qwen_SFT_0622', '--logging_steps', '10', '--micro_train_batch_size', '16', '--train_batch_size', '128', '--pretrain', '/data2/rlhf/lixs/open_models/Qwen2-7B-Instruct/', '--bf16', '--max_epochs', '1', '--max_len', '6400', '--zero_stage', '3', '--eval_steps', '250', '--learning_rate', '1e-5', '--dataset', '/data2/rlhf/yzy/analysis/output/gpt-4-preview.train.jsonl', '--eval_dataset', '/data2/rlhf/yzy/analysis/output/gpt-4-preview.valid.jsonl', '--dataset_probs', '1.0', '--flash_attn', '--gradient_checkpointing', '--use_wandb', 'a77607626908409e45afa2ca225cf179e9a316fc', '--wandb_run_name', 'Qwen_SFT_0622', '--wandb_project', 'rl']
[2024-06-22 15:12:25,531] [INFO] [launch.py:256:main] process 109495 spawned with command: ['/data2/rlhf/liufeng/miniconda3/envs/yzy-rl-dev/bin/python', '-u', '../../examples/train_sft.py', '--local_rank=5', '--save_path', '/data2/rlhf/yzy/OpenRLHF-new/outputs/reward_models/Qwen_SFT_0622', '--logging_steps', '10', '--micro_train_batch_size', '16', '--train_batch_size', '128', '--pretrain', '/data2/rlhf/lixs/open_models/Qwen2-7B-Instruct/', '--bf16', '--max_epochs', '1', '--max_len', '6400', '--zero_stage', '3', '--eval_steps', '250', '--learning_rate', '1e-5', '--dataset', '/data2/rlhf/yzy/analysis/output/gpt-4-preview.train.jsonl', '--eval_dataset', '/data2/rlhf/yzy/analysis/output/gpt-4-preview.valid.jsonl', '--dataset_probs', '1.0', '--flash_attn', '--gradient_checkpointing', '--use_wandb', 'a77607626908409e45afa2ca225cf179e9a316fc', '--wandb_run_name', 'Qwen_SFT_0622', '--wandb_project', 'rl']
[2024-06-22 15:12:25,531] [INFO] [launch.py:256:main] process 109496 spawned with command: ['/data2/rlhf/liufeng/miniconda3/envs/yzy-rl-dev/bin/python', '-u', '../../examples/train_sft.py', '--local_rank=6', '--save_path', '/data2/rlhf/yzy/OpenRLHF-new/outputs/reward_models/Qwen_SFT_0622', '--logging_steps', '10', '--micro_train_batch_size', '16', '--train_batch_size', '128', '--pretrain', '/data2/rlhf/lixs/open_models/Qwen2-7B-Instruct/', '--bf16', '--max_epochs', '1', '--max_len', '6400', '--zero_stage', '3', '--eval_steps', '250', '--learning_rate', '1e-5', '--dataset', '/data2/rlhf/yzy/analysis/output/gpt-4-preview.train.jsonl', '--eval_dataset', '/data2/rlhf/yzy/analysis/output/gpt-4-preview.valid.jsonl', '--dataset_probs', '1.0', '--flash_attn', '--gradient_checkpointing', '--use_wandb', 'a77607626908409e45afa2ca225cf179e9a316fc', '--wandb_run_name', 'Qwen_SFT_0622', '--wandb_project', 'rl']
[2024-06-22 15:12:25,531] [INFO] [launch.py:256:main] process 109497 spawned with command: ['/data2/rlhf/liufeng/miniconda3/envs/yzy-rl-dev/bin/python', '-u', '../../examples/train_sft.py', '--local_rank=7', '--save_path', '/data2/rlhf/yzy/OpenRLHF-new/outputs/reward_models/Qwen_SFT_0622', '--logging_steps', '10', '--micro_train_batch_size', '16', '--train_batch_size', '128', '--pretrain', '/data2/rlhf/lixs/open_models/Qwen2-7B-Instruct/', '--bf16', '--max_epochs', '1', '--max_len', '6400', '--zero_stage', '3', '--eval_steps', '250', '--learning_rate', '1e-5', '--dataset', '/data2/rlhf/yzy/analysis/output/gpt-4-preview.train.jsonl', '--eval_dataset', '/data2/rlhf/yzy/analysis/output/gpt-4-preview.valid.jsonl', '--dataset_probs', '1.0', '--flash_attn', '--gradient_checkpointing', '--use_wandb', 'a77607626908409e45afa2ca225cf179e9a316fc', '--wandb_run_name', 'Qwen_SFT_0622', '--wandb_project', 'rl']
Traceback (most recent call last):
  File "/data2/rlhf/yzy/OpenRLHF-new/run_scripts/0620/../../examples/train_sft.py", line 8, in <module>
    from openrlhf.datasets import SFTDataset, MySFTDataset
ModuleNotFoundError: No module named 'openrlhf'
[2024-06-22 15:12:35,532] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 109490
[2024-06-22 15:12:35,629] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 109491
[2024-06-22 15:12:35,629] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 109492
Traceback (most recent call last):
  File "/data2/rlhf/yzy/OpenRLHF-new/run_scripts/0620/../../examples/train_sft.py", line 8, in <module>
    from openrlhf.datasets import SFTDataset, MySFTDataset
ModuleNotFoundError: No module named 'openrlhf'
[2024-06-22 15:12:35,724] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 109493
[2024-06-22 15:12:35,819] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 109494
[2024-06-22 15:12:35,915] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 109495
Traceback (most recent call last):
  File "/data2/rlhf/yzy/OpenRLHF-new/run_scripts/0620/../../examples/train_sft.py", line 8, in <module>
    from openrlhf.datasets import SFTDataset, MySFTDataset
ModuleNotFoundError: No module named 'openrlhf'
[2024-06-22 15:12:36,010] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 109496
[2024-06-22 15:12:36,145] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 109497
[2024-06-22 15:12:36,281] [ERROR] [launch.py:325:sigkill_handler] ['/data2/rlhf/liufeng/miniconda3/envs/yzy-rl-dev/bin/python', '-u', '../../examples/train_sft.py', '--local_rank=7', '--save_path', '/data2/rlhf/yzy/OpenRLHF-new/outputs/reward_models/Qwen_SFT_0622', '--logging_steps', '10', '--micro_train_batch_size', '16', '--train_batch_size', '128', '--pretrain', '/data2/rlhf/lixs/open_models/Qwen2-7B-Instruct/', '--bf16', '--max_epochs', '1', '--max_len', '6400', '--zero_stage', '3', '--eval_steps', '250', '--learning_rate', '1e-5', '--dataset', '/data2/rlhf/yzy/analysis/output/gpt-4-preview.train.jsonl', '--eval_dataset', '/data2/rlhf/yzy/analysis/output/gpt-4-preview.valid.jsonl', '--dataset_probs', '1.0', '--flash_attn', '--gradient_checkpointing', '--use_wandb', 'a77607626908409e45afa2ca225cf179e9a316fc', '--wandb_run_name', 'Qwen_SFT_0622', '--wandb_project', 'rl'] exits with return code = 1
